{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0xs1d/pwskills/blob/main/SVM_Naive_Bayes_FULL_assignment_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "213416db",
      "metadata": {
        "id": "213416db"
      },
      "source": [
        "# SVM & Naïve Bayes — Complete Assignment Solutions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d382dd91",
      "metadata": {
        "id": "d382dd91"
      },
      "source": [
        "## 1. What is a Support Vector Machine (SVM)?\n",
        "\n",
        "SVM is a supervised learning algorithm used for classification and regression. It finds an optimal hyperplane that separates classes with the maximum margin, ensuring better generalization."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cc8dfe2",
      "metadata": {
        "id": "2cc8dfe2"
      },
      "source": [
        "## 2. Difference between Hard Margin and Soft Margin SVM\n",
        "\n",
        "Hard Margin SVM assumes perfectly separable data with no misclassification allowed. Soft Margin SVM allows some misclassification using slack variables, making it suitable for noisy data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "346469be",
      "metadata": {
        "id": "346469be"
      },
      "source": [
        "## 3. Mathematical intuition behind SVM\n",
        "\n",
        "SVM solves an optimization problem that maximizes the margin while minimizing classification error. It focuses only on critical points (support vectors)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9e6c160",
      "metadata": {
        "id": "b9e6c160"
      },
      "source": [
        "## 4. Role of Lagrange Multipliers in SVM\n",
        "\n",
        "Lagrange multipliers convert the constrained optimization problem into a dual form, making kernel-based computation possible."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5eb642c0",
      "metadata": {
        "id": "5eb642c0"
      },
      "source": [
        "## 5. Support Vectors in SVM\n",
        "\n",
        "Support vectors are data points closest to the decision boundary. They directly influence the position of the hyperplane."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b70e3a70",
      "metadata": {
        "id": "b70e3a70"
      },
      "source": [
        "## 6. Support Vector Classifier (SVC)\n",
        "\n",
        "SVC is the classification version of SVM used to separate categorical classes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40841c91",
      "metadata": {
        "id": "40841c91"
      },
      "source": [
        "## 7. Support Vector Regressor (SVR)\n",
        "\n",
        "SVR is an SVM variant used for regression tasks, minimizing error within an epsilon margin."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94ea402c",
      "metadata": {
        "id": "94ea402c"
      },
      "source": [
        "## 8. Kernel Trick in SVM\n",
        "\n",
        "The kernel trick maps data into higher dimensions to handle non‑linear separation without explicit transformation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71e64eec",
      "metadata": {
        "id": "71e64eec"
      },
      "source": [
        "## 9. Linear vs Polynomial vs RBF Kernel\n",
        "\n",
        "Linear works for linearly separable data, Polynomial captures curved boundaries, and RBF handles complex non‑linear patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caead947",
      "metadata": {
        "id": "caead947"
      },
      "source": [
        "## 10. Effect of C parameter in SVM\n",
        "\n",
        "C controls the trade‑off between margin width and misclassification. High C means fewer errors, low C means wider margin."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a590385d",
      "metadata": {
        "id": "a590385d"
      },
      "source": [
        "## 11. Role of Gamma in RBF Kernel\n",
        "\n",
        "Gamma controls how far the influence of a single point reaches. High gamma causes overfitting; low gamma smooths decision boundaries."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e7eb1d2",
      "metadata": {
        "id": "4e7eb1d2"
      },
      "source": [
        "## 12. Naïve Bayes classifier\n",
        "\n",
        "Naïve Bayes is a probabilistic classifier based on Bayes’ Theorem assuming feature independence."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e54a9dd",
      "metadata": {
        "id": "2e54a9dd"
      },
      "source": [
        "## 13. Bayes’ Theorem\n",
        "\n",
        "Bayes’ Theorem calculates conditional probability: P(A|B) = P(B|A)P(A)/P(B)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f32a1b49",
      "metadata": {
        "id": "f32a1b49"
      },
      "source": [
        "## 14. Gaussian vs Multinomial vs Bernoulli Naïve Bayes\n",
        "\n",
        "Gaussian is used for continuous data, Multinomial for text/count data, and Bernoulli for binary features."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca462963",
      "metadata": {
        "id": "ca462963"
      },
      "source": [
        "## 15. When to use Gaussian Naïve Bayes\n",
        "\n",
        "Use Gaussian Naïve Bayes when features are continuous and approximately normally distributed."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0419fa98",
      "metadata": {
        "id": "0419fa98"
      },
      "source": [
        "## 16. Key assumptions of Naïve Bayes\n",
        "\n",
        "Features are conditionally independent and equally important."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a34e3c8",
      "metadata": {
        "id": "0a34e3c8"
      },
      "source": [
        "## 17. Advantages and disadvantages of Naïve Bayes\n",
        "\n",
        "Advantages: fast, simple, works well with large data. Disadvantages: strong independence assumption."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67c09699",
      "metadata": {
        "id": "67c09699"
      },
      "source": [
        "## 18. Why Naïve Bayes is good for text classification\n",
        "\n",
        "It handles high‑dimensional sparse data efficiently and performs well with word frequencies."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "947142a2",
      "metadata": {
        "id": "947142a2"
      },
      "source": [
        "## 19. Compare SVM and Naïve Bayes\n",
        "\n",
        "SVM offers higher accuracy but is computationally expensive, while Naïve Bayes is faster but less expressive."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07d69434",
      "metadata": {
        "id": "07d69434"
      },
      "source": [
        "## 20. Laplace Smoothing in Naïve Bayes\n",
        "\n",
        "Laplace smoothing avoids zero probabilities by adding a small constant to feature counts."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81ea3915",
      "metadata": {
        "id": "81ea3915"
      },
      "source": [
        "## 27. SVM with different C values (decision boundary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b937ed31",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b937ed31",
        "outputId": "2fe054ea-6d98-40ce-e08a-22f6931fb335"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C=0.1, Accuracy=0.80\n",
            "C=1, Accuracy=0.82\n",
            "C=10, Accuracy=0.82\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris, load_breast_cancer, load_wine\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve, roc_auc_score\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X = X[:, :2]\n",
        "\n",
        "for C in [0.1, 1, 10]:\n",
        "    model = SVC(C=C, kernel='linear')\n",
        "    model.fit(X, y)\n",
        "    print(f\"C={C}, Accuracy={model.score(X,y):.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a93f1586",
      "metadata": {
        "id": "a93f1586"
      },
      "source": [
        "## 28. Bernoulli Naïve Bayes for binary classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3befd6cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3befd6cf",
        "outputId": "9379d02a-465f-4289-e853-1ffd014c66d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7996485061511424\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris, load_breast_cancer, load_wine\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve, roc_auc_score\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X = (X > X.mean()).astype(int)\n",
        "\n",
        "model = BernoulliNB()\n",
        "model.fit(X, y)\n",
        "print(\"Accuracy:\", model.score(X, y))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c953419",
      "metadata": {
        "id": "8c953419"
      },
      "source": [
        "## 29. Feature scaling before SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "79c4b1e7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79c4b1e7",
        "outputId": "a1e3fe05-7184-4dda-984e-a878caf9b9ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unscaled: 0.9210526315789473\n",
            "Scaled: 0.8947368421052632\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris, load_breast_cancer, load_wine\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve, roc_auc_score\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "svm_unscaled = SVC().fit(X_train, y_train)\n",
        "svm_scaled = Pipeline([('scaler', StandardScaler()), ('svm', SVC())]).fit(X_train, y_train)\n",
        "\n",
        "print(\"Unscaled:\", svm_unscaled.score(X_test, y_test))\n",
        "print(\"Scaled:\", svm_scaled.score(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "995f515a",
      "metadata": {
        "id": "995f515a"
      },
      "source": [
        "## 30. Gaussian NB before and after Laplace smoothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0c44c550",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c44c550",
        "outputId": "30a5afa8-f1d7-41c1-c10b-71f9d54b24ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris, load_breast_cancer, load_wine\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve, roc_auc_score\n",
        "\n",
        "model = GaussianNB(var_smoothing=1e-9)\n",
        "X, y = load_iris(return_X_y=True)\n",
        "model.fit(X, y)\n",
        "print(\"Predictions:\", model.predict(X[:5]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2ef6b14",
      "metadata": {
        "id": "d2ef6b14"
      },
      "source": [
        "## 31. GridSearchCV for SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3625ac5f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3625ac5f",
        "outputId": "5759c318-aa25-4c5f-a2ad-e3533bc7b65c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Params: {'C': 1, 'kernel': 'linear'}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris, load_breast_cancer, load_wine\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve, roc_auc_score\n",
        "\n",
        "params = {'C':[0.1,1,10], 'kernel':['linear','rbf']}\n",
        "grid = GridSearchCV(SVC(), params, cv=5)\n",
        "X, y = load_iris(return_X_y=True)\n",
        "grid.fit(X, y)\n",
        "print(\"Best Params:\", grid.best_params_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa8b43d3",
      "metadata": {
        "id": "fa8b43d3"
      },
      "source": [
        "## 32. SVM on imbalanced data with class weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e681f7a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e681f7a1",
        "outputId": "ba49d3ff-e5b2-46d8-c27b-f26351b22948"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9103690685413005\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris, load_breast_cancer, load_wine\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve, roc_auc_score\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "model = SVC(class_weight='balanced')\n",
        "model.fit(X, y)\n",
        "print(\"Accuracy:\", model.score(X, y))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c495a24",
      "metadata": {
        "id": "3c495a24"
      },
      "source": [
        "## 33. Naïve Bayes spam detection (demo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "2ebbf60d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ebbf60d",
        "outputId": "783a0d66-4782-4482-9beb-6ea6a9e39fda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: [1]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris, load_breast_cancer, load_wine\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve, roc_auc_score\n",
        "\n",
        "X = [[1,0,1],[0,1,0],[1,1,1]]\n",
        "y = [1,0,1]\n",
        "model = BernoulliNB()\n",
        "model.fit(X, y)\n",
        "print(\"Prediction:\", model.predict([[1,0,0]]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d7bb15b",
      "metadata": {
        "id": "5d7bb15b"
      },
      "source": [
        "## 34. Compare SVM and Naïve Bayes accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2a14db43",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a14db43",
        "outputId": "b43f0081-fae0-420e-d965-d8a249a11e8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM: 0.9733333333333334\n",
            "NB: 0.96\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris, load_breast_cancer, load_wine\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve, roc_auc_score\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "print(\"SVM:\", SVC().fit(X,y).score(X,y))\n",
        "print(\"NB:\", GaussianNB().fit(X,y).score(X,y))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7872e0a",
      "metadata": {
        "id": "c7872e0a"
      },
      "source": [
        "## 36. OvR vs OvO on Wine dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "80442416",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80442416",
        "outputId": "b2f251c4-638b-4ac6-8426-31bcae22fa80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OvR: 0.7078651685393258\n",
            "OvO: 0.7078651685393258\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris, load_breast_cancer, load_wine\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve, roc_auc_score\n",
        "\n",
        "X, y = load_wine(return_X_y=True)\n",
        "print(\"OvR:\", SVC(decision_function_shape='ovr').fit(X,y).score(X,y))\n",
        "print(\"OvO:\", SVC(decision_function_shape='ovo').fit(X,y).score(X,y))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff40a082",
      "metadata": {
        "id": "ff40a082"
      },
      "source": [
        "## 37. Kernel comparison on Breast Cancer dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "fc5593e8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc5593e8",
        "outputId": "53944c0b-fd84-4add-813f-344f7e8afc3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear 0.9666080843585237\n",
            "poly 0.9138840070298769\n",
            "rbf 0.9226713532513181\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris, load_breast_cancer, load_wine\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve, roc_auc_score\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "for k in ['linear','poly','rbf']:\n",
        "    print(k, SVC(kernel=k).fit(X,y).score(X,y))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38ed482b",
      "metadata": {
        "id": "38ed482b"
      },
      "source": [
        "## 38. Stratified K‑Fold CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b3436542",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3436542",
        "outputId": "414a7deb-bc7f-4ebd-e60c-7461905ddd9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.9666666666666666\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris, load_breast_cancer, load_wine\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve, roc_auc_score\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "scores = cross_val_score(SVC(), X, y, cv=StratifiedKFold(5))\n",
        "print(\"Average Accuracy:\", scores.mean())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "858af87d",
      "metadata": {
        "id": "858af87d"
      },
      "source": [
        "## 41. Precision‑Recall & F1 evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f98c8c07",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f98c8c07",
        "outputId": "3bc37e85-d4da-4863-95c9-a28725654a80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9226713532513181\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris, load_breast_cancer, load_wine\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve, roc_auc_score\n",
        "\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "model = SVC()\n",
        "model.fit(X,y)\n",
        "print(\"Accuracy:\", model.score(X,y))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}